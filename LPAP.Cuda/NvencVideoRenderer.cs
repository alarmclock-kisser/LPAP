#nullable enable
using LPAP.Audio;
using LPAP.Audio.Processing;
using System;
using System.Buffers;
using System.Collections.Generic;
using System.Diagnostics;
using System.Drawing;
using System.Drawing.Imaging;
using System.Globalization;
using System.IO;
using System.Linq;
using System.Runtime.InteropServices;
using System.Text;
using System.Threading;
using System.Threading.Channels;
using System.Threading.Tasks;

namespace LPAP.Cuda
{
    public static class NvencVideoRenderer
    {
        public sealed record NvencOptions(
            string VideoCodec,            // "h264_nvenc" oder "hevc_nvenc"
            string Preset,                // z.B. "p5" (neuere ffmpeg/nvenc)
            int? VideoBitrateKbps,         // null => CQ (wenn gesetzt) oder ffmpeg default
            int? MaxBitrateKbps,           // optional
            int? BufferSizeKbps,           // optional
            int? ConstantQuality,          // CQ (0..51 h264, 0..63 hevc), null => bitrate mode
            string? Profile,               // z.B. "high" für h264
            bool FastStart                 // -movflags +faststart
        )
        {
            public static NvencOptions H264Default => new(
                VideoCodec: "h264_nvenc",
                Preset: "p5",
                VideoBitrateKbps: null,
                MaxBitrateKbps: null,
                BufferSizeKbps: null,
                ConstantQuality: 20,
                Profile: "high",
                FastStart: true
            );

            public static NvencOptions HevcDefault => new(
                VideoCodec: "hevc_nvenc",
                Preset: "p5",
                VideoBitrateKbps: null,
                MaxBitrateKbps: null,
                BufferSizeKbps: null,
                ConstantQuality: 22,
                Profile: null,
                FastStart: true
            );
        }

        public static readonly string[] CommonResolutions =
        [
            "3840x2160",
            "2560x1440",
            "1920x1080",
            "1280x720",
            "854x480",
            "640x360",
            "426x240",
            "256x144"
        ];

        // ------------------------------------------------------------
        // Public: Image[] + optional Audio-File
        // ------------------------------------------------------------

        public static Task<string?> NvencRenderVideoAsync(
            Image[] frames,
            int width = 0,
            int height = 0,
            float frameRate = 20.0f,
            string? audioFilePath = null,
            string? outputFilePath = null,
            IProgress<double>? progress = null,
            CancellationToken? ct = null)
            => NvencRenderVideoAsync(
                frames: frames,
                width: width,
                height: height,
                frameRate: frameRate,
                audioFilePath: audioFilePath,
                outputFilePath: outputFilePath,
                options: NvencOptions.H264Default,
                progress: progress,
                ct: ct);

        public static async Task<string?> NvencRenderVideoAsync(
            Image[] frames,
            int width,
            int height,
            float frameRate,
            string? audioFilePath,
            string? outputFilePath,
            NvencOptions options,
            IProgress<double>? progress = null,
            CancellationToken? ct = null)
        {
            if (frames is null || frames.Length == 0)
            {
                throw new ArgumentException("frames darf nicht null/leer sein.", nameof(frames));
            }

            var token = ct ?? CancellationToken.None;

            // 1) Dimensionen bestimmen
            if (width <= 0 || height <= 0)
            {
                GetMaxDimensions(frames, out var maxW, out var maxH);
                if (width <= 0)
                {
                    width = maxW;
                }

                if (height <= 0)
                {
                    height = maxH;
                }
            }

            if (width <= 0 || height <= 0)
            {
                throw new ArgumentOutOfRangeException("width/height müssen > 0 sein (oder aus Frames ableitbar).");
            }

            // 2) Audio prüfen + ggf. frameRate aus Audiolänge setzen
            TimeSpan? audioDuration = null;
            if (!string.IsNullOrWhiteSpace(audioFilePath))
            {
                audioFilePath = Path.GetFullPath(audioFilePath);
                if (!File.Exists(audioFilePath))
                {
                    throw new FileNotFoundException("audioFilePath existiert nicht.", audioFilePath);
                }

                try
                {
#if NAUDIO
					using var afr = new NAudio.Wave.AudioFileReader(audioFilePath);
					audioDuration = afr.TotalTime;
#else
                    audioDuration = null;
#endif
                }
                catch
                {
                    audioDuration = null;
                }

                if (frameRate <= 0 && audioDuration.HasValue && audioDuration.Value.TotalSeconds > 0.001)
                {
                    frameRate = (float) (frames.Length / audioDuration.Value.TotalSeconds);
                    if (frameRate < 1e-3f)
                    {
                        frameRate = 20.0f;
                    }
                }
            }

            if (frameRate <= 0)
            {
                throw new ArgumentOutOfRangeException(nameof(frameRate),
                    "frameRate muss > 0 sein, außer Audio-Dauer konnte ermittelt werden.");
            }

            // 3) Output-Pfad bestimmen
            var resolvedOutputPath = ResolveOutputPath(outputFilePath);
            Directory.CreateDirectory(Path.GetDirectoryName(resolvedOutputPath)!);

            // 4) Gesamtdauer für Progress
            var totalVideoSeconds = frames.Length / (double) frameRate;
            var totalSeconds = audioDuration.HasValue && audioDuration.Value.TotalSeconds > 0.001
                ? Math.Max(totalVideoSeconds, audioDuration.Value.TotalSeconds)
                : totalVideoSeconds;

            progress?.Report(0.0);

            // 5) FFmpeg args (Video stdin raw BGRA)
            var args = BuildFfmpegArgs(
                width, height, frameRate,
                audioFilePath,
                resolvedOutputPath,
                options);

            var psi = new ProcessStartInfo
            {
                FileName = "ffmpeg",
                Arguments = args,
                UseShellExecute = false,
                RedirectStandardInput = true,
                RedirectStandardOutput = true, // progress kommt hier rein -> MUSS gelesen werden
                RedirectStandardError = true,  // MUSS gelesen werden
                CreateNoWindow = true
            };

            using var proc = new Process { StartInfo = psi, EnableRaisingEvents = true };
            var stderrSb = new StringBuilder();

            try
            {
                if (!proc.Start())
                {
                    throw new InvalidOperationException("FFmpeg konnte nicht gestartet werden.");
                }

                // stderr drain (sonst deadlock möglich)
                var stderrTask = Task.Run(async () =>
                {
                    try
                    {
                        string? line;
                        while ((line = await proc.StandardError.ReadLineAsync().ConfigureAwait(false)) != null)
                        {
                            stderrSb.AppendLine(line);
                        }
                    }
                    catch { }
                }, token);

                // progress drain (sonst deadlock wegen -progress pipe:1)
                var progressTask = Task.Run(async () =>
                {
                    try
                    {
                        string? line;
                        double lastReported = 0.0;

                        while ((line = await proc.StandardOutput.ReadLineAsync().ConfigureAwait(false)) != null)
                        {
                            if (line.StartsWith("out_time_ms=", StringComparison.OrdinalIgnoreCase))
                            {
                                var val = line["out_time_ms=".Length..].Trim();
                                if (long.TryParse(val, NumberStyles.Integer, CultureInfo.InvariantCulture, out var outMs))
                                {
                                    var sec = outMs / 1_000_000.0;
                                    var p = totalSeconds > 0 ? sec / totalSeconds : 0.0;
                                    p = Math.Clamp(p, 0.0, 1.0);

                                    if (p >= lastReported + 0.002 || p >= 1.0)
                                    {
                                        lastReported = p;
                                        progress?.Report(p);
                                    }
                                }
                            }
                        }
                    }
                    catch { }
                }, token);

                await WriteFramesToStdinAsync(proc, frames, width, height, token).ConfigureAwait(false);

                try { proc.StandardInput.Close(); } catch { }

                await proc.WaitForExitAsync(token).ConfigureAwait(false);

                try { await Task.WhenAll(stderrTask, progressTask).ConfigureAwait(false); } catch { }

                if (proc.ExitCode != 0)
                {
                    SafeDelete(resolvedOutputPath);
                    throw new InvalidOperationException($"FFmpeg exit code {proc.ExitCode}. Details:\n{stderrSb}");
                }

                progress?.Report(1.0);
                return resolvedOutputPath;
            }
            catch (OperationCanceledException)
            {
                TryKill(proc);
                SafeDelete(resolvedOutputPath);
                throw;
            }
            catch
            {
                TryKill(proc);
                SafeDelete(resolvedOutputPath);
                throw;
            }
        }

        // ------------------------------------------------------------
        // Public: Image[] + AudioObj (RAM -> NamedPipe raw PCM)
        // ------------------------------------------------------------

        public static Task<string?> NvencRenderVideoAsync(
            Image[] frames,
            int width,
            int height,
            float frameRate,
            AudioObj audio,
            string? outputFilePath = null,
            NvencOptions? options = null,
            IProgress<double>? progress = null,
            CancellationToken? ct = null)
        {
            if (audio is null)
            {
                throw new ArgumentNullException(nameof(audio));
            }

            if (audio.Data is null)
            {
                throw new ArgumentException("audio.Data ist null.", nameof(audio));
            }

            return NvencRenderVideoWithRawAudioAsync(
                frames,
                width,
                height,
                frameRate,
                audio.Data,
                audio.SampleRate,
                audio.Channels,
                outputFilePath,
                options ?? NvencOptions.H264Default,
                progress,
                ct);
        }

        public static Task<string?> NvencRenderVideoAsync(
            Image[] frames,
            int width,
            int height,
            float frameRate,
            float[] audioData,
            int audioSampleRate,
            int audioChannels,
            string? outputFilePath = null,
            NvencOptions? options = null,
            IProgress<double>? progress = null,
            CancellationToken? ct = null)
        {
            if (audioData is null)
            {
                throw new ArgumentNullException(nameof(audioData));
            }

            if (audioSampleRate <= 0)
            {
                throw new ArgumentOutOfRangeException(nameof(audioSampleRate));
            }

            if (audioChannels <= 0)
            {
                throw new ArgumentOutOfRangeException(nameof(audioChannels));
            }

            return NvencRenderVideoWithRawAudioAsync(
                frames,
                width,
                height,
                frameRate,
                audioData,
                audioSampleRate,
                audioChannels,
                outputFilePath,
                options ?? NvencOptions.H264Default,
                progress,
                ct);
        }

        // ------------------------------------------------------------
        // Public: FramesDir + AudioObj (lazy disk -> stdin + audio pipe)
        // ------------------------------------------------------------

        public static async Task<string?> NvencRenderVideoAsync(
            string framesDir,
            int width,
            int height,
            float frameRate,
            AudioObj audio,
            string searchPattern = "*.png",
            string? outputFilePath = null,
            NvencOptions? options = null,
            IProgress<double>? progress = null,
            CancellationToken? ct = null)
        {
            if (string.IsNullOrWhiteSpace(framesDir))
            {
                throw new ArgumentNullException(nameof(framesDir));
            }

            if (!Directory.Exists(framesDir))
            {
                throw new DirectoryNotFoundException(framesDir);
            }

            if (width <= 0)
            {
                throw new ArgumentOutOfRangeException(nameof(width));
            }

            if (height <= 0)
            {
                throw new ArgumentOutOfRangeException(nameof(height));
            }

            if (audio is null)
            {
                throw new ArgumentNullException(nameof(audio));
            }

            if (audio.Data is null)
            {
                throw new ArgumentException("audio.Data ist null.", nameof(audio));
            }

            var token = ct ?? CancellationToken.None;

            var files = Directory.EnumerateFiles(framesDir, searchPattern, SearchOption.TopDirectoryOnly)
                .OrderBy(p => p, StringComparer.OrdinalIgnoreCase)
                .ToArray();

            if (files.Length == 0)
            {
                throw new InvalidOperationException($"Keine Frames gefunden in '{framesDir}' (Pattern '{searchPattern}').");
            }

            return await NvencRenderVideoFromFileListAsync(
                files, width, height, frameRate, audio,
                outputFilePath, options ?? NvencOptions.H264Default,
                progress, token).ConfigureAwait(false);
        }

        // ------------------------------------------------------------
        // Public: ChannelReader (Producer→Consumer Pipeline) + AudioObj
        // ------------------------------------------------------------

        public static Task<string?> NvencRenderVideoAsync(
            ChannelReader<AudioProcessor.FramePacket> frames,
            int frameCount,
            int width,
            int height,
            float frameRate,
            AudioObj audio,
            string? outputFilePath = null,
            NvencOptions? options = null,
            IProgress<double>? progress = null,
            CancellationToken? ct = null)
        {
            if (frames is null)
            {
                throw new ArgumentNullException(nameof(frames));
            }

            if (audio is null)
            {
                throw new ArgumentNullException(nameof(audio));
            }

            if (audio.Data is null)
            {
                throw new ArgumentException("audio.Data ist null.", nameof(audio));
            }

            if (frameCount <= 0)
            {
                throw new ArgumentOutOfRangeException(nameof(frameCount));
            }

            if (width <= 0)
            {
                throw new ArgumentOutOfRangeException(nameof(width));
            }

            if (height <= 0)
            {
                throw new ArgumentOutOfRangeException(nameof(height));
            }

            if (frameRate <= 0)
            {
                throw new ArgumentOutOfRangeException(nameof(frameRate));
            }

            return NvencRenderVideoFromChannelAsync(
                frames, frameCount, width, height, frameRate,
                audio,
                outputFilePath,
                options ?? NvencOptions.H264Default,
                progress,
                ct ?? CancellationToken.None);
        }

        // ------------------------------------------------------------
        // Core: Channel -> stdin (ordered) + raw audio pipe
        // ------------------------------------------------------------

        private static async Task<string?> NvencRenderVideoFromChannelAsync(
            ChannelReader<AudioProcessor.FramePacket> reader,
            int frameCount,
            int width,
            int height,
            float frameRate,
            AudioObj audio,
            string? outputFilePath,
            NvencOptions options,
            IProgress<double>? progress,
            CancellationToken token)
        {
            string output = ResolveOutputPath(outputFilePath);
            Directory.CreateDirectory(Path.GetDirectoryName(output)!);

            int expectedLen = checked(width * height * 4);

            float[] sourceAudio = audio.Data;
            int audioSampleRate = audio.SampleRate;
            int audioChannels = audio.Channels;

            double audioSeconds = (sourceAudio.Length > 0 && audioSampleRate > 0 && audioChannels > 0)
                ? (sourceAudio.Length / (double) audioChannels) / audioSampleRate
                : 0.0;

            double totalVideoSeconds = frameCount / (double) frameRate;
            double totalSeconds = audioSeconds > 0.001 ? Math.Max(totalVideoSeconds, audioSeconds) : totalVideoSeconds;

            progress?.Report(0.0);

            string pipeName = "lpap_nvenc_audio_" + Guid.NewGuid().ToString("N");
            string pipePath = $@"\\.\pipe\{pipeName}";

            string args = BuildFfmpegArgsWithRawAudioPipe(
                width, height, frameRate,
                pipePath, audioSampleRate, audioChannels,
                output,
                options);

            var psi = new ProcessStartInfo
            {
                FileName = "ffmpeg",
                Arguments = args,
                UseShellExecute = false,
                RedirectStandardInput = true,
                RedirectStandardOutput = true, // progress pipe:1 -> MUSS gelesen werden!
                RedirectStandardError = true,  // MUSS gelesen werden!
                CreateNoWindow = true
            };

            using var proc = new Process { StartInfo = psi, EnableRaisingEvents = true };
            var stderrSb = new StringBuilder();

            using var audioPipe = new System.IO.Pipes.NamedPipeServerStream(
                pipeName,
                System.IO.Pipes.PipeDirection.Out,
                1,
                System.IO.Pipes.PipeTransmissionMode.Byte,
                System.IO.Pipes.PipeOptions.Asynchronous);

            try
            {
                if (!proc.Start())
                {
                    throw new InvalidOperationException("FFmpeg konnte nicht gestartet werden.");
                }

                var stderrTask = Task.Run(async () =>
                {
                    try
                    {
                        string? line;
                        while ((line = await proc.StandardError.ReadLineAsync().ConfigureAwait(false)) != null)
                        {
                            stderrSb.AppendLine(line);
                        }
                    }
                    catch { }
                }, token);

                var progressTask = Task.Run(async () =>
                {
                    try
                    {
                        string? line;
                        double last = 0.0;
                        while ((line = await proc.StandardOutput.ReadLineAsync().ConfigureAwait(false)) != null)
                        {
                            if (line.StartsWith("out_time_ms=", StringComparison.OrdinalIgnoreCase))
                            {
                                var val = line["out_time_ms=".Length..].Trim();
                                if (long.TryParse(val, NumberStyles.Integer, CultureInfo.InvariantCulture, out var outMs))
                                {
                                    var sec = outMs / 1_000_000.0;
                                    var p = totalSeconds > 0 ? sec / totalSeconds : 0.0;
                                    p = Math.Clamp(p, 0.0, 1.0);

                                    if (p >= last + 0.002 || p >= 1.0)
                                    {
                                        last = p;
                                        progress?.Report(p);
                                    }
                                }
                            }
                        }
                    }
                    catch { }
                }, token);

                var audioTask = Task.Run(async () =>
                {
                    token.ThrowIfCancellationRequested();
                    await audioPipe.WaitForConnectionAsync(token).ConfigureAwait(false);

                    const int floatsPerChunk = 8192;
                    var byteBuf = ArrayPool<byte>.Shared.Rent(floatsPerChunk * 2);

                    try
                    {
                        int i = 0;
                        while (i < sourceAudio.Length)
                        {
                            token.ThrowIfCancellationRequested();

                            int count = Math.Min(floatsPerChunk, sourceAudio.Length - i);
                            int bi = 0;

                            for (int k = 0; k < count; k++)
                            {
                                float f = sourceAudio[i + k];
                                if (f > 1f)
                                {
                                    f = 1f;
                                }
                                else if (f < -1f)
                                {
                                    f = -1f;
                                }

                                short s = (short) Math.Round(f * 32767f);
                                byteBuf[bi++] = (byte) (s & 0xFF);
                                byteBuf[bi++] = (byte) ((s >> 8) & 0xFF);
                            }

                            await audioPipe.WriteAsync(byteBuf.AsMemory(0, bi), token).ConfigureAwait(false);
                            i += count;
                        }

                        await audioPipe.FlushAsync(token).ConfigureAwait(false);
                    }
                    finally
                    {
                        ArrayPool<byte>.Shared.Return(byteBuf);
                        try { audioPipe.Dispose(); } catch { }
                    }
                }, token);

                await WriteFramePacketsToStdinOrderedAsync(
                    proc.StandardInput.BaseStream,
                    reader,
                    frameCount,
                    expectedLen,
                    token).ConfigureAwait(false);

                try { proc.StandardInput.Close(); } catch { }

                await proc.WaitForExitAsync(token).ConfigureAwait(false);

                try { await Task.WhenAll(stderrTask, progressTask, audioTask).ConfigureAwait(false); } catch { }

                if (proc.ExitCode != 0)
                {
                    SafeDelete(output);
                    throw new InvalidOperationException($"FFmpeg exit code {proc.ExitCode}. Details:\n{stderrSb}");
                }

                progress?.Report(1.0);
                return output;
            }
            catch (OperationCanceledException)
            {
                TryKill(proc);
                SafeDelete(output);
                throw;
            }
            catch
            {
                TryKill(proc);
                SafeDelete(output);
                throw;
            }
        }

        private static async Task WriteFramePacketsToStdinOrderedAsync(
            Stream stdin,
            ChannelReader<AudioProcessor.FramePacket> reader,
            int frameCount,
            int expectedLen,
            CancellationToken token)
        {
            var pending = new Dictionary<int, AudioProcessor.FramePacket>(capacity: Math.Min(frameCount, 1024));
            int next = 0;

            try
            {
                await foreach (var pkt in reader.ReadAllAsync(token).ConfigureAwait(false))
                {
                    if (pkt.Length != expectedLen)
                    {
                        ArrayPool<byte>.Shared.Return(pkt.Buffer);
                        throw new InvalidOperationException($"Frame size mismatch: got {pkt.Length}, expected {expectedLen}");
                    }

                    pending[pkt.Index] = pkt;

                    while (pending.TryGetValue(next, out var cur))
                    {
                        pending.Remove(next);

                        await stdin.WriteAsync(cur.Buffer.AsMemory(0, cur.Length), token).ConfigureAwait(false);
                        ArrayPool<byte>.Shared.Return(cur.Buffer);

                        next++;
                        if (next >= frameCount)
                        {
                            return; // fertig sobald frameCount geschrieben
                        }
                    }
                }

                if (next < frameCount)
                {
                    throw new InvalidOperationException($"Channel completed early. Missing frames: {frameCount - next}");
                }
            }
            finally
            {
                foreach (var kv in pending)
                {
                    try { ArrayPool<byte>.Shared.Return(kv.Value.Buffer); } catch { }
                }
                pending.Clear();
            }
        }

        // ------------------------------------------------------------
        // Core: Image[] -> stdin (raw BGRA)
        // ------------------------------------------------------------

        private static async Task WriteFramesToStdinAsync(
            Process proc,
            Image[] frames,
            int targetW,
            int targetH,
            CancellationToken token)
        {
            int frameBytes = checked(targetW * targetH * 4);
            byte[] buffer = ArrayPool<byte>.Shared.Rent(frameBytes);

            try
            {
                using var stdin = proc.StandardInput.BaseStream;
                using var canvas = new Bitmap(targetW, targetH, PixelFormat.Format32bppArgb);

                for (int i = 0; i < frames.Length; i++)
                {
                    token.ThrowIfCancellationRequested();

                    var frame = frames[i];
                    if (frame == null)
                    {
                        continue;
                    }

                    using (var g = Graphics.FromImage(canvas))
                    {
                        g.Clear(Color.Black);
                        g.DrawImage(frame, 0, 0, frame.Width, frame.Height);
                    }

                    CopyBitmap32bppArgbToBgraBuffer(canvas, buffer, frameBytes);
                    await stdin.WriteAsync(buffer.AsMemory(0, frameBytes), token).ConfigureAwait(false);
                }
            }
            finally
            {
                ArrayPool<byte>.Shared.Return(buffer);
            }
        }

        // ------------------------------------------------------------
        // Core: Raw-Audio Pipe + Image[] Frames
        // ------------------------------------------------------------

        private static async Task<string?> NvencRenderVideoWithRawAudioAsync(
            Image[] frames,
            int width,
            int height,
            float frameRate,
            float[] audioData,
            int audioSampleRate,
            int audioChannels,
            string? outputFilePath,
            NvencOptions options,
            IProgress<double>? progress,
            CancellationToken? ct)
        {
            if (frames is null || frames.Length == 0)
            {
                throw new ArgumentException("frames darf nicht null/leer sein.", nameof(frames));
            }

            var token = ct ?? CancellationToken.None;

            // Dimensionen bestimmen
            if (width <= 0 || height <= 0)
            {
                GetMaxDimensions(frames, out var maxW, out var maxH);
                if (width <= 0)
                {
                    width = maxW;
                }

                if (height <= 0)
                {
                    height = maxH;
                }
            }
            if (width <= 0 || height <= 0)
            {
                throw new ArgumentOutOfRangeException("width/height müssen > 0 sein (oder aus Frames ableitbar).");
            }

            // Audio Dauer (RAM)
            double audioSeconds = 0;
            if (audioData.Length > 0 && audioSampleRate > 0 && audioChannels > 0)
            {
                audioSeconds = (audioData.Length / (double) audioChannels) / audioSampleRate;
            }

            // frameRate <= 0 => an Audio anpassen
            if (frameRate <= 0 && audioSeconds > 0.001)
            {
                frameRate = (float) (frames.Length / audioSeconds);
                if (frameRate < 1e-3f)
                {
                    frameRate = 20.0f;
                }
            }
            if (frameRate <= 0)
            {
                throw new ArgumentOutOfRangeException(nameof(frameRate), "frameRate muss > 0 sein (oder Audio muss gültig sein).");
            }

            var resolvedOutputPath = ResolveOutputPath(outputFilePath);
            Directory.CreateDirectory(Path.GetDirectoryName(resolvedOutputPath)!);

            var totalVideoSeconds = frames.Length / (double) frameRate;
            var totalSeconds = audioSeconds > 0.001 ? Math.Max(totalVideoSeconds, audioSeconds) : totalVideoSeconds;
            progress?.Report(0.0);

            string pipeName = "lpap_nvenc_audio_" + Guid.NewGuid().ToString("N");
            string pipePath = $@"\\.\pipe\{pipeName}";

            var args = BuildFfmpegArgsWithRawAudioPipe(
                width, height, frameRate,
                pipePath, audioSampleRate, audioChannels,
                resolvedOutputPath,
                options);

            var psi = new ProcessStartInfo
            {
                FileName = "ffmpeg",
                Arguments = args,
                UseShellExecute = false,
                RedirectStandardInput = true,
                RedirectStandardOutput = true, // progress pipe:1
                RedirectStandardError = true,
                CreateNoWindow = true
            };

            using var proc = new Process { StartInfo = psi, EnableRaisingEvents = true };
            var stderrSb = new StringBuilder();

            using var audioPipe = new System.IO.Pipes.NamedPipeServerStream(
                pipeName,
                System.IO.Pipes.PipeDirection.Out,
                1,
                System.IO.Pipes.PipeTransmissionMode.Byte,
                System.IO.Pipes.PipeOptions.Asynchronous);

            try
            {
                if (!proc.Start())
                {
                    throw new InvalidOperationException("FFmpeg konnte nicht gestartet werden.");
                }

                var stderrTask = Task.Run(async () =>
                {
                    try
                    {
                        string? line;
                        while ((line = await proc.StandardError.ReadLineAsync().ConfigureAwait(false)) != null)
                        {
                            stderrSb.AppendLine(line);
                        }
                    }
                    catch { }
                }, token);

                var progressTask = Task.Run(async () =>
                {
                    try
                    {
                        string? line;
                        double lastReported = 0.0;

                        while ((line = await proc.StandardOutput.ReadLineAsync().ConfigureAwait(false)) != null)
                        {
                            if (line.StartsWith("out_time_ms=", StringComparison.OrdinalIgnoreCase))
                            {
                                var val = line["out_time_ms=".Length..].Trim();
                                if (long.TryParse(val, NumberStyles.Integer, CultureInfo.InvariantCulture, out var outMs))
                                {
                                    var sec = outMs / 1_000_000.0;
                                    var p = totalSeconds > 0 ? sec / totalSeconds : 0.0;
                                    p = Math.Clamp(p, 0.0, 1.0);

                                    if (p >= lastReported + 0.002 || p >= 1.0)
                                    {
                                        lastReported = p;
                                        progress?.Report(p);
                                    }
                                }
                            }
                        }
                    }
                    catch { }
                }, token);

                var audioTask = Task.Run(async () =>
                {
                    token.ThrowIfCancellationRequested();
                    await audioPipe.WaitForConnectionAsync(token).ConfigureAwait(false);

                    const int floatsPerChunk = 8192;
                    var byteBuf = ArrayPool<byte>.Shared.Rent(floatsPerChunk * 2);

                    try
                    {
                        int i = 0;
                        while (i < audioData.Length)
                        {
                            token.ThrowIfCancellationRequested();

                            int count = Math.Min(floatsPerChunk, audioData.Length - i);
                            int bi = 0;

                            for (int k = 0; k < count; k++)
                            {
                                float f = audioData[i + k];
                                if (f > 1f)
                                {
                                    f = 1f;
                                }
                                else if (f < -1f)
                                {
                                    f = -1f;
                                }

                                short s = (short) Math.Round(f * 32767f);
                                byteBuf[bi++] = (byte) (s & 0xFF);
                                byteBuf[bi++] = (byte) ((s >> 8) & 0xFF);
                            }

                            await audioPipe.WriteAsync(byteBuf.AsMemory(0, bi), token).ConfigureAwait(false);
                            i += count;
                        }

                        await audioPipe.FlushAsync(token).ConfigureAwait(false);
                    }
                    finally
                    {
                        ArrayPool<byte>.Shared.Return(byteBuf);
                        try { audioPipe.Dispose(); } catch { }
                    }
                }, token);

                await WriteFramesToStdinAsync(proc, frames, width, height, token).ConfigureAwait(false);

                try { proc.StandardInput.Close(); } catch { }

                await proc.WaitForExitAsync(token).ConfigureAwait(false);

                try { await Task.WhenAll(stderrTask, progressTask, audioTask).ConfigureAwait(false); } catch { }

                if (proc.ExitCode != 0)
                {
                    SafeDelete(resolvedOutputPath);
                    throw new InvalidOperationException($"FFmpeg exit code {proc.ExitCode}. Details:\n{stderrSb}");
                }

                progress?.Report(1.0);
                return resolvedOutputPath;
            }
            catch (OperationCanceledException)
            {
                TryKill(proc);
                SafeDelete(resolvedOutputPath);
                throw;
            }
            catch
            {
                TryKill(proc);
                SafeDelete(resolvedOutputPath);
                throw;
            }
        }

        // ------------------------------------------------------------
        // Core: FramesDir file list -> stdin + raw audio pipe
        // ------------------------------------------------------------

        private static async Task<string?> NvencRenderVideoFromFileListAsync(
            string[] frameFiles,
            int width,
            int height,
            float frameRate,
            AudioObj audio,
            string? outputFilePath,
            NvencOptions options,
            IProgress<double>? progress,
            CancellationToken token)
        {
            float[] sourceAudio = audio.Data;
            int audioSampleRate = audio.SampleRate;
            int audioChannels = audio.Channels;

            double audioSeconds = (sourceAudio.Length > 0 && audioSampleRate > 0 && audioChannels > 0)
                ? (sourceAudio.Length / (double) audioChannels) / audioSampleRate
                : 0.0;

            if (frameRate <= 0 && audioSeconds > 0.001)
            {
                frameRate = (float) (frameFiles.Length / audioSeconds);
            }

            if (frameRate <= 0)
            {
                throw new ArgumentOutOfRangeException(nameof(frameRate), "frameRate muss > 0 sein (oder Audio muss gültig sein).");
            }

            var resolvedOutputPath = ResolveOutputPath(outputFilePath);
            Directory.CreateDirectory(Path.GetDirectoryName(resolvedOutputPath)!);

            var totalVideoSeconds = frameFiles.Length / (double) frameRate;
            var totalSeconds = audioSeconds > 0.001 ? Math.Max(totalVideoSeconds, audioSeconds) : totalVideoSeconds;

            progress?.Report(0.0);

            string pipeName = "lpap_nvenc_audio_" + Guid.NewGuid().ToString("N");
            string pipePath = $@"\\.\pipe\{pipeName}";

            var args = BuildFfmpegArgsWithRawAudioPipe(
                width, height, frameRate,
                pipePath, audioSampleRate, audioChannels,
                resolvedOutputPath,
                options);

            var psi = new ProcessStartInfo
            {
                FileName = "ffmpeg",
                Arguments = args,
                UseShellExecute = false,
                RedirectStandardInput = true,
                RedirectStandardOutput = true,
                RedirectStandardError = true,
                CreateNoWindow = true
            };

            using var proc = new Process { StartInfo = psi, EnableRaisingEvents = true };
            var stderrSb = new StringBuilder();

            using var audioPipe = new System.IO.Pipes.NamedPipeServerStream(
                pipeName,
                System.IO.Pipes.PipeDirection.Out,
                1,
                System.IO.Pipes.PipeTransmissionMode.Byte,
                System.IO.Pipes.PipeOptions.Asynchronous);

            try
            {
                if (!proc.Start())
                {
                    throw new InvalidOperationException("FFmpeg konnte nicht gestartet werden.");
                }

                var stderrTask = Task.Run(async () =>
                {
                    try
                    {
                        string? line;
                        while ((line = await proc.StandardError.ReadLineAsync().ConfigureAwait(false)) != null)
                        {
                            stderrSb.AppendLine(line);
                        }
                    }
                    catch { }
                }, token);

                var progressTask = Task.Run(async () =>
                {
                    try
                    {
                        string? line;
                        double last = 0.0;
                        while ((line = await proc.StandardOutput.ReadLineAsync().ConfigureAwait(false)) != null)
                        {
                            if (line.StartsWith("out_time_ms=", StringComparison.OrdinalIgnoreCase))
                            {
                                var val = line["out_time_ms=".Length..].Trim();
                                if (long.TryParse(val, NumberStyles.Integer, CultureInfo.InvariantCulture, out var outMs))
                                {
                                    var sec = outMs / 1_000_000.0;
                                    var p = totalSeconds > 0 ? sec / totalSeconds : 0.0;
                                    p = Math.Clamp(p, 0.0, 1.0);
                                    if (p >= last + 0.002 || p >= 1.0)
                                    {
                                        last = p;
                                        progress?.Report(p);
                                    }
                                }
                            }
                        }
                    }
                    catch { }
                }, token);

                var audioTask = Task.Run(async () =>
                {
                    token.ThrowIfCancellationRequested();
                    await audioPipe.WaitForConnectionAsync(token).ConfigureAwait(false);

                    const int floatsPerChunk = 8192;
                    var byteBuf = ArrayPool<byte>.Shared.Rent(floatsPerChunk * 2);

                    try
                    {
                        int i = 0;
                        while (i < sourceAudio.Length)
                        {
                            token.ThrowIfCancellationRequested();

                            int count = Math.Min(floatsPerChunk, sourceAudio.Length - i);
                            int bi = 0;

                            for (int k = 0; k < count; k++)
                            {
                                float f = sourceAudio[i + k];
                                if (f > 1f)
                                {
                                    f = 1f;
                                }
                                else if (f < -1f)
                                {
                                    f = -1f;
                                }

                                short s = (short) Math.Round(f * 32767f);
                                byteBuf[bi++] = (byte) (s & 0xFF);
                                byteBuf[bi++] = (byte) ((s >> 8) & 0xFF);
                            }

                            await audioPipe.WriteAsync(byteBuf.AsMemory(0, bi), token).ConfigureAwait(false);
                            i += count;
                        }

                        await audioPipe.FlushAsync(token).ConfigureAwait(false);
                    }
                    finally
                    {
                        ArrayPool<byte>.Shared.Return(byteBuf);
                    }
                }, token);

                await WriteFrameFilesToStdinAsync(proc, frameFiles, width, height, token).ConfigureAwait(false);

                try { proc.StandardInput.Close(); } catch { }

                await proc.WaitForExitAsync(token).ConfigureAwait(false);

                try { await Task.WhenAll(stderrTask, progressTask, audioTask).ConfigureAwait(false); } catch { }

                if (proc.ExitCode != 0)
                {
                    SafeDelete(resolvedOutputPath);
                    throw new InvalidOperationException($"FFmpeg exit code {proc.ExitCode}. Details:\n{stderrSb}");
                }

                progress?.Report(1.0);
                return resolvedOutputPath;
            }
            catch (OperationCanceledException)
            {
                TryKill(proc);
                SafeDelete(resolvedOutputPath);
                throw;
            }
            catch
            {
                TryKill(proc);
                SafeDelete(resolvedOutputPath);
                throw;
            }
        }

        private static async Task WriteFrameFilesToStdinAsync(
            Process proc,
            string[] frameFiles,
            int targetW,
            int targetH,
            CancellationToken token)
        {
            int frameBytes = checked(targetW * targetH * 4);
            var buffer = ArrayPool<byte>.Shared.Rent(frameBytes);

            try
            {
                using var stdin = proc.StandardInput.BaseStream;
                using var canvas = new Bitmap(targetW, targetH, PixelFormat.Format32bppArgb);

                for (int i = 0; i < frameFiles.Length; i++)
                {
                    token.ThrowIfCancellationRequested();

                    using var fs = new FileStream(frameFiles[i], FileMode.Open, FileAccess.Read, FileShare.Read);
                    using var tmp = Image.FromStream(fs, useEmbeddedColorManagement: false, validateImageData: false);
                    using var img = (Image) tmp.Clone();

                    using (var g = Graphics.FromImage(canvas))
                    {
                        g.Clear(Color.Black);
                        g.DrawImage(img, 0, 0, img.Width, img.Height);
                    }

                    CopyBitmap32bppArgbToBgraBuffer(canvas, buffer, frameBytes);
                    await stdin.WriteAsync(buffer.AsMemory(0, frameBytes), token).ConfigureAwait(false);
                }
            }
            finally
            {
                ArrayPool<byte>.Shared.Return(buffer);
            }
        }

        // ------------------------------------------------------------
        // Utilities
        // ------------------------------------------------------------

        private static void CopyBitmap32bppArgbToBgraBuffer(Bitmap bmp, byte[] dst, int expectedBytes)
        {
            if (bmp.PixelFormat != PixelFormat.Format32bppArgb)
            {
                throw new ArgumentException("Bitmap muss Format32bppArgb sein.");
            }

            var rect = new Rectangle(0, 0, bmp.Width, bmp.Height);
            var data = bmp.LockBits(rect, ImageLockMode.ReadOnly, PixelFormat.Format32bppArgb);
            try
            {
                int stride = data.Stride;
                int rowBytes = bmp.Width * 4;

                if (rowBytes * bmp.Height != expectedBytes)
                {
                    throw new InvalidOperationException("Frame byte size mismatch.");
                }

                unsafe
                {
                    byte* srcBase = (byte*) data.Scan0;
                    int di = 0;

                    fixed (byte* dstBase = dst)
                    {
                        for (int y = 0; y < bmp.Height; y++)
                        {
                            Buffer.MemoryCopy(
                                source: srcBase + (y * stride),
                                destination: dstBase + di,
                                destinationSizeInBytes: rowBytes,
                                sourceBytesToCopy: rowBytes);
                            di += rowBytes;
                        }
                    }
                }
            }
            finally
            {
                bmp.UnlockBits(data);
            }
        }

        private static string BuildFfmpegArgs(
            int width,
            int height,
            float frameRate,
            string? audioFilePath,
            string outputPath,
            NvencOptions options)
        {
            var sb = new StringBuilder();

            sb.Append("-hide_banner -nostats ");
            sb.Append("-loglevel error ");
            sb.Append("-progress pipe:1 ");

            sb.Append(CultureInfo.InvariantCulture,
                $"-f rawvideo -pix_fmt bgra -s {width}x{height} -r {frameRate:0.########} -i pipe:0 ");

            if (!string.IsNullOrWhiteSpace(audioFilePath))
            {
                sb.Append($"-i \"{audioFilePath}\" ");
            }

            sb.Append($"-c:v {options.VideoCodec} ");

            if (!string.IsNullOrWhiteSpace(options.Preset))
            {
                sb.Append($"-preset {options.Preset} ");
            }

            if (options.ConstantQuality.HasValue)
            {
                sb.Append(CultureInfo.InvariantCulture, $"-cq:v {options.ConstantQuality.Value} ");
            }
            else if (options.VideoBitrateKbps.HasValue)
            {
                sb.Append(CultureInfo.InvariantCulture, $"-b:v {options.VideoBitrateKbps.Value}k ");
                if (options.MaxBitrateKbps.HasValue)
                {
                    sb.Append(CultureInfo.InvariantCulture, $"-maxrate {options.MaxBitrateKbps.Value}k ");
                }

                if (options.BufferSizeKbps.HasValue)
                {
                    sb.Append(CultureInfo.InvariantCulture, $"-bufsize {options.BufferSizeKbps.Value}k ");
                }
            }

            if (!string.IsNullOrWhiteSpace(options.Profile))
            {
                sb.Append($"-profile:v {options.Profile} ");
            }

            sb.Append("-pix_fmt yuv420p ");

            if (!string.IsNullOrWhiteSpace(audioFilePath))
            {
                sb.Append("-c:a aac -b:a 192k -shortest ");
            }

            if (options.FastStart)
            {
                sb.Append("-movflags +faststart ");
            }

            sb.Append("-y ");
            sb.Append($"\"{outputPath}\"");

            return sb.ToString();
        }

        private static string BuildFfmpegArgsWithRawAudioPipe(
            int width,
            int height,
            float frameRate,
            string audioPipePath,
            int audioSampleRate,
            int audioChannels,
            string outputPath,
            NvencOptions options)
        {
            var sb = new StringBuilder();

            sb.Append("-hide_banner -nostats ");
            sb.Append("-loglevel error ");
            sb.Append("-progress pipe:1 ");

            sb.Append(CultureInfo.InvariantCulture,
                $"-f rawvideo -pix_fmt bgra -s {width}x{height} -r {frameRate:0.########} -i pipe:0 ");

            sb.Append(CultureInfo.InvariantCulture,
                $"-f s16le -ar {audioSampleRate} -ac {audioChannels} -i \"{audioPipePath}\" ");

            sb.Append($"-c:v {options.VideoCodec} ");

            if (!string.IsNullOrWhiteSpace(options.Preset))
            {
                sb.Append($"-preset {options.Preset} ");
            }

            if (options.ConstantQuality.HasValue)
            {
                sb.Append(CultureInfo.InvariantCulture, $"-cq:v {options.ConstantQuality.Value} ");
            }
            else if (options.VideoBitrateKbps.HasValue)
            {
                sb.Append(CultureInfo.InvariantCulture, $"-b:v {options.VideoBitrateKbps.Value}k ");
                if (options.MaxBitrateKbps.HasValue)
                {
                    sb.Append(CultureInfo.InvariantCulture, $"-maxrate {options.MaxBitrateKbps.Value}k ");
                }

                if (options.BufferSizeKbps.HasValue)
                {
                    sb.Append(CultureInfo.InvariantCulture, $"-bufsize {options.BufferSizeKbps.Value}k ");
                }
            }

            if (!string.IsNullOrWhiteSpace(options.Profile))
            {
                sb.Append($"-profile:v {options.Profile} ");
            }

            sb.Append("-pix_fmt yuv420p ");
            sb.Append("-c:a aac -b:a 192k -shortest ");

            if (options.FastStart)
            {
                sb.Append("-movflags +faststart ");
            }

            sb.Append("-y ");
            sb.Append($"\"{outputPath}\"");

            return sb.ToString();
        }

        private static void GetMaxDimensions(Image[] frames, out int maxW, out int maxH)
        {
            maxW = 0; maxH = 0;
            for (int i = 0; i < frames.Length; i++)
            {
                if (frames[i] is null)
                {
                    continue;
                }

                if (frames[i].Width > maxW)
                {
                    maxW = frames[i].Width;
                }

                if (frames[i].Height > maxH)
                {
                    maxH = frames[i].Height;
                }
            }
        }

        private static string ResolveOutputPath(string? outputFilePath)
        {
            string baseDir = Path.Combine(
                Environment.GetFolderPath(Environment.SpecialFolder.MyVideos),
                "NVenc_Output");

            Directory.CreateDirectory(baseDir);

            string defaultFileName =
                "NVenc_" + DateTime.Now.ToString("yyyyMMdd_HHmmss", CultureInfo.InvariantCulture) + ".mp4";

            if (string.IsNullOrWhiteSpace(outputFilePath))
            {
                return Path.Combine(baseDir, defaultFileName);
            }

            outputFilePath = Path.GetFullPath(outputFilePath);

            if (Directory.Exists(outputFilePath))
            {
                return Path.Combine(outputFilePath, defaultFileName);
            }

            if (outputFilePath.EndsWith(Path.DirectorySeparatorChar) ||
                outputFilePath.EndsWith(Path.AltDirectorySeparatorChar))
            {
                Directory.CreateDirectory(outputFilePath);
                return Path.Combine(outputFilePath, defaultFileName);
            }

            string dir = Path.GetDirectoryName(outputFilePath)!;
            if (!string.IsNullOrWhiteSpace(dir))
            {
                Directory.CreateDirectory(dir);
            }

            if (!outputFilePath.EndsWith(".mp4", StringComparison.OrdinalIgnoreCase))
            {
                outputFilePath += ".mp4";
            }

            return outputFilePath;
        }

        private static void TryKill(Process p)
        {
            try
            {
                if (!p.HasExited)
                {
                    p.Kill(entireProcessTree: true);
                }
            }
            catch { }
        }

        private static void SafeDelete(string path)
        {
            try
            {
                if (File.Exists(path))
                {
                    File.Delete(path);
                }
            }
            catch { }
        }

        // ------------------------------------------------------------
        // Extra helpers you already had (BuildImageFromBytes + LoadImagesParallel)
        // (unverändert, amplitude-unrelated)
        // ------------------------------------------------------------

        public static Task<Image?> BuildImageFromBytesAsync(byte[] data, int width, int height,
            string channelCode = "BGRA", CancellationToken ct = default)
        {
            if (data is null)
            {
                throw new ArgumentNullException(nameof(data));
            }

            if (width <= 0)
            {
                throw new ArgumentOutOfRangeException(nameof(width));
            }

            if (height <= 0)
            {
                throw new ArgumentOutOfRangeException(nameof(height));
            }

            if (string.IsNullOrWhiteSpace(channelCode))
            {
                throw new ArgumentException("channelCode darf nicht leer sein.", nameof(channelCode));
            }

            channelCode = channelCode.Trim().ToUpperInvariant();

            return Task.Run(() =>
            {
                ct.ThrowIfCancellationRequested();

                int channels = channelCode.Length;
                if (channels is not (1 or 3 or 4))
                {
                    return (Image?) null;
                }

                long expected = (long) width * height * channels;
                if (data.LongLength != expected)
                {
                    return (Image?) null;
                }

                PixelFormat pf = channels switch
                {
                    4 => PixelFormat.Format32bppArgb,
                    3 => PixelFormat.Format24bppRgb,
                    1 => PixelFormat.Format8bppIndexed,
                    _ => throw new InvalidOperationException()
                };

                Bitmap bmp = new(width, height, pf);

                try
                {
                    if (channels == 1)
                    {
                        var pal = bmp.Palette;
                        for (int i = 0; i < 256; i++)
                        {
                            pal.Entries[i] = Color.FromArgb(i, i, i);
                        }

                        bmp.Palette = pal;
                    }

                    var rect = new Rectangle(0, 0, width, height);
                    var bd = bmp.LockBits(rect, ImageLockMode.WriteOnly, pf);

                    try
                    {
                        ct.ThrowIfCancellationRequested();

                        int dstStride = bd.Stride;
                        int srcStride = width * channels;

                        unsafe
                        {
                            byte* dstBase = (byte*) bd.Scan0;

                            fixed (byte* srcBase0 = data)
                            {
                                for (int y = 0; y < height; y++)
                                {
                                    ct.ThrowIfCancellationRequested();

                                    byte* dstRow = dstBase + (y * dstStride);
                                    byte* srcRow = srcBase0 + (y * srcStride);

                                    if (channels == 4)
                                    {
                                        for (int x = 0; x < width; x++)
                                        {
                                            byte c0 = srcRow[x * 4 + 0];
                                            byte c1 = srcRow[x * 4 + 1];
                                            byte c2 = srcRow[x * 4 + 2];
                                            byte c3 = srcRow[x * 4 + 3];

                                            (byte b, byte g, byte r, byte a) = Map4(channelCode, c0, c1, c2, c3);

                                            int di = x * 4;
                                            dstRow[di + 0] = b;
                                            dstRow[di + 1] = g;
                                            dstRow[di + 2] = r;
                                            dstRow[di + 3] = a;
                                        }
                                    }
                                    else if (channels == 3)
                                    {
                                        for (int x = 0; x < width; x++)
                                        {
                                            byte c0 = srcRow[x * 3 + 0];
                                            byte c1 = srcRow[x * 3 + 1];
                                            byte c2 = srcRow[x * 3 + 2];

                                            (byte b, byte g, byte r) = Map3(channelCode, c0, c1, c2);

                                            int di = x * 3;
                                            dstRow[di + 0] = b;
                                            dstRow[di + 1] = g;
                                            dstRow[di + 2] = r;
                                        }
                                    }
                                    else
                                    {
                                        Marshal.Copy(data, y * srcStride, (IntPtr) dstRow, srcStride);
                                    }
                                }
                            }
                        }
                    }
                    finally
                    {
                        bmp.UnlockBits(bd);
                    }

                    return (Image) bmp;
                }
                catch
                {
                    bmp.Dispose();
                    return null;
                }

            }, ct);

            static (byte b, byte g, byte r, byte a) Map4(string code, byte c0, byte c1, byte c2, byte c3) => code switch
            {
                "BGRA" => (c0, c1, c2, c3),
                "RGBA" => (c2, c1, c0, c3),
                "ARGB" => (c3, c2, c1, c0),
                "ABGR" => (c1, c2, c3, c0),
                _ => (c0, c1, c2, c3)
            };

            static (byte b, byte g, byte r) Map3(string code, byte c0, byte c1, byte c2) => code switch
            {
                "BGR" => (c0, c1, c2),
                "RGB" => (c2, c1, c0),
                _ => (c0, c1, c2)
            };
        }

        public static async Task<Image[]> LoadImagesParallelAsync(
            string[] imageFilePaths,
            string? imagesDir = null,
            int maxWorkers = 0,
            IProgress<double>? progress = null,
            CancellationToken ct = default)
        {
            if (imageFilePaths is null)
            {
                throw new ArgumentNullException(nameof(imageFilePaths));
            }

            if (imageFilePaths.Length == 0)
            {
                return Array.Empty<Image>();
            }

            maxWorkers = maxWorkers <= 0
                ? Environment.ProcessorCount
                : Math.Clamp(maxWorkers, 1, Environment.ProcessorCount);

            string? baseDir = string.IsNullOrWhiteSpace(imagesDir) ? null : Path.GetFullPath(imagesDir);

            var paths = imageFilePaths
                .Where(p => !string.IsNullOrWhiteSpace(p))
                .Select(p =>
                {
                    var trimmed = p.Trim();
                    if (Path.IsPathRooted(trimmed))
                    {
                        return Path.GetFullPath(trimmed);
                    }

                    if (baseDir != null)
                    {
                        return Path.GetFullPath(Path.Combine(baseDir, trimmed));
                    }

                    return Path.GetFullPath(trimmed);
                })
                .ToArray();

            int total = paths.Length;
            if (total == 0)
            {
                return Array.Empty<Image>();
            }

            progress?.Report(0);

            var gate = new SemaphoreSlim(maxWorkers, maxWorkers);
            var results = new Image?[total];
            int done = 0;

            var tasks = new Task[total];

            for (int i = 0; i < total; i++)
            {
                int idx = i;
                string path = paths[idx];

                tasks[idx] = Task.Run(async () =>
                {
                    await gate.WaitAsync(ct).ConfigureAwait(false);
                    try
                    {
                        ct.ThrowIfCancellationRequested();

                        if (!File.Exists(path))
                        {
                            return;
                        }

                        using var fs = new FileStream(path, FileMode.Open, FileAccess.Read, FileShare.Read);
                        using var tmp = Image.FromStream(fs, useEmbeddedColorManagement: false, validateImageData: false);
                        results[idx] = (Image) tmp.Clone();
                    }
                    catch { }
                    finally
                    {
                        gate.Release();
                        int now = Interlocked.Increment(ref done);
                        progress?.Report(now / (double) total);
                    }
                }, ct);
            }

            await Task.WhenAll(tasks).ConfigureAwait(false);

            return results.Where(img => img != null).Cast<Image>().ToArray();
        }
    }
}
